# DeReverbIC: A TDUNET-Based Two-Stage Framework for RIR Blind Estimation

This repository contains the implementation of DeReverbIC, a deep learning-based approach for blind estimation of room impulse response (RIR) from reverberant speech.

## Environment

The following software and hardware environment was used for this project. However, it should also work on other environments, including different GPUs and operating systems like Windows.

### Software

We use Anaconda to manage the environments on Linux (Anolis OS 8.6), with CUDA 12.4. Visual Studio Code is used for remote development and is highly recommended for reproducing this project to ensure a more consistent experience.

```shell
conda create -n Dereverbic python=3.12.8
conda activate Dereverbic
conda install conda-forge::ffmpeg=7.1.0
pip install torch==2.5.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124
pip install -r other_requirements.txt
```

### Hardware

The hardware used is as follows (not all resources are occupied):

- CPU: 7x Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz
    - Memory: 128800M
- GPU: 1x NVIDIA L40
    - Memory: 46068MiB

## Running the Project

### Project Structure

To ensure consistent module importing, `./src/` is treated as the root directory. Therefore, `PYTHONPATH` should be set to `./src/`, otherwise the modules may not be imported correctly. When using Visual Studio Code, there is no need to modify it manually, as `python.envFile` has been configured in the workspace. (This only takes effect for the Python extension. An additional setting of `PYTHONPATH` is still required when running in the terminal.) Note that relative paths are used in the project, so it is recommended to keep the working directory at `Dereverbic--RirBlindEstimation/` to ensure consistency across all scripts.

All executable scripts are placed under the `./src/exe/` directory. Other scripts will be imported by these executables to complete the corresponding tasks. A `common_configurations.py` exists in `./src/exe/` to allow convenient modification of settings that may need to be changed on different devices, including the storage locations for datasets and checkpoints, as well as the GPU to be used.

In addition, each executable script has a corresponding `_config.py` to store its configurations. Using Python scripts for configuration allows options to be easily reused and located. When using Visual Studio Code, these configuration scripts will be nested according to the `explorer.fileNesting`. All configuration scripts are designed to be interrelated with previous ones. For example, when the checkpoint location is modified in `train_dereverbic_config.py`, the value provided in `validate_dereverbic_config.py` will also change accordingly.

### Data Preparation

#### Downloading the RIR Dataset

[The BIRD dataset](https://arxiv.org/abs/2010.09930) is used to provide RIRs: https://github.com/FrancoisGrondin/BIRD

For convenience, the BIRD dataset can be downloaded using `./src/exe/data/download/download_bird.py`. The storage location is specified by `./src/exe/data/download/download_bird_config.py`, with the default being `./data/raw/bird/`.

#### Downloading the Speech Dataset

[The EARS dataset](https://www.isca-archive.org/interspeech_2024/richter24_interspeech.html) is used to provide anechoic speech: https://github.com/facebookresearch/ears_dataset

Similarly, the EARS dataset can be downloaded using `./src/exe/data/download/download_ears.py`, with the default storage location being `./data/raw/ears/`.

#### Data Preprocessing

The downloaded data needs to be processed and converted into `.wav.pt` files for subsequent training and testing.

- RIR preprocessing: `./src/exe/data/preprocess/convert_rir_to_tensor.py`
- Speech preprocessing: `./src/exe/data/preprocess/convert_speech_to_tensor.py`

These preprocessing scripts may not be applicable for other datasets, as some steps may depend on certain characteristics of the datasets. For example, it is assumed that all data in the RIR dataset have a uniform length and thus do not require trimming.

Next, `./src/exe/data/preprocess/split_dataset.py` can be used to split the dataset. This script is generic as long as the files generated by the above preprocessing scripts meet its required format.

`./src/exe/data/preprocess/convert_wav_pt_to_wav.py` can be used to convert the generated `.wav.pt` files back to `.wav` files.

### Model Training and Testing

#### Training DeReverbIC

Taking our proposed DeReverbIC model as an example, training can be started by `train_dereverbic.py` in `./src/exe/dereverbic/dereverbic/`. Checkpoints are saved by default to the `./checkpoints/dereverbic/` directory. Training will not stop until the process is terminated.

#### Validating and Testing DeReverbIC

After training is complete, the model can be validated with the validation set using `validate_dereverbic.py`. Once validation is finished, a `validation_rank.txt` file will be automatically placed in the checkpoint directory, recording the ranking of checkpoints based on their performance on the validation set. When running `test_dereverbic.py` for testing, the best checkpoint will be used automatically. Validation and testing will automatically stop after running once on the respective datasets.

#### Model List

Training and testing for other models are consistent with DeReverbIC. We have included all baseline models in this repository, including the RIR blind estimation models mentioned in the paper:
- FiNS: `./src/exe/fins/`
- BERP: `./src/exe/berp/`
- CleanUNet: `./src/exe/cleanunet/dbe/`
- CleanUNet w/ Two Stage: `./src/exe/cleanunet/two_stage/`
- DeReverbIC w/o Two Stage: `./src/exe/dereverbic/tdunet_dbe/`
- DeReverbIC: `./src/exe/dereverbic/dereverbic`

And the RIR inverse convolution models:
- TDUNET w/o $\mathcal{F}_\mathrm{ed}$: `./src/exe/dereverbic/tdunet_ric_without_energy_decay/`
- TDUNET: `./src/exe/dereverbic/tdunet_ric/`

#### Additional Experiments

In addition to the experiments covered in the paper, some other models and experiments were also tested and performed.

More approaches of RIR inverse convolution:
- Frequency-Domain Division: `./src/exe/frequency_domain_division/`
- CleanUNet: `./src/exe/cleanunet/ric/`

Experiments of de-reverberation:
- CleanUNet: `./src/exe/cleanunet/cleanunet/`
- TDUNET: `./src/exe/dereverbic/tdunet_dereverb/`

## Terms

To simplify the code, some terms may differ from that in the paper or commonly used ones, including but not limited to the following:
- `speech`: It only refers to anechoic speech.
- `reverb`: It refers to reverberant speech.
- `epoch`: Since the dataset is very large, each iteration randomly selects data rather than following a predetermined order. During training, the concepts of epoch, batch, and iteration are used interchangeably.

---

> Since the relevant paper has not yet been published, some content is not convenient to be made public, including the pre-trained models, open source license, results of the additional experiments, etc. We will promptly supplement the relevant information after the paper is accepted.